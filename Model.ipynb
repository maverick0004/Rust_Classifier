{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leVqn7AvJFRh",
        "colab_type": "text"
      },
      "source": [
        "We use following tools\n",
        "\n",
        "1. Python 3\n",
        "2. Jupyter Notebook\n",
        "3. Azure CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FW5FZoKJFRi",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuIYJEMUJFRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.applications import ResNet50,InceptionResNetV2\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D,GlobalMaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zdkXri0JFRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = 'rustdata2'\n",
        "sz = 224\n",
        "batch_size = 4\n",
        "train_data_dir = f'{PATH}train' \n",
        "validation_data_dir = f'{PATH}valid'\n",
        "\n",
        "#data augmentations for training data\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,vertical_flip=True,rotation_range=90)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "    target_size=(sz, sz),\n",
        "    batch_size=batch_size, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    shuffle=False,\n",
        "    target_size=(sz, sz),\n",
        "    batch_size=batch_size, class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETlgtM4GJFRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using InceptionResNetV2 as base model pre trained on imagenet\n",
        "base_model = InceptionResNetV2(weights = 'imagenet',include_top=False,input_shape=(sz,sz,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk2ahM9FJFRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BkZCttOJFRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers[:500]: \n",
        "  layer.trainable = False\n",
        "for layer in base_model.layers[500:]: \n",
        "  layer.trainable = True\n",
        "model.compile(optimizer=optimizers.SGD(lr=0.001), loss='categorical_crossentropy'\n",
        "              , metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBHj8H4jJFRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator, train_generator.n // batch_size\n",
        ", epochs=3,workers=4,validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ftB2yF-JFRw",
        "colab_type": "text"
      },
      "source": [
        "# Model Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM--jUWiJFRx",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbl45tZsJFRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from azureml.core import Experiment, Run, Workspace\n",
        "import azureml.core\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n",
        "\n",
        "ws = Workspace(resource_group='DemoGroup',workspace_name='demospace',subscription_id='5959c85b-cacb-4c20-b1fb-e47c40ed5aff')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPdJX8p9JFR0",
        "colab_type": "text"
      },
      "source": [
        "### Save the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H_ARA25JFR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('kerasmodel.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j7YfPnNJFR3",
        "colab_type": "text"
      },
      "source": [
        "### Register a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4btbCDUBJFR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from azureml.core.model import Model\n",
        "model_name = \"kerasmodel\"\n",
        "model_path = \"./kerasmodel.pkl\"\n",
        "\n",
        "model = Model.register(\n",
        "    model_path=model_path,\n",
        "    model_name=model_name,\n",
        "    tags={\"data\": \"rust\", \"model\": \"classification\"},\n",
        "    description=\"Classifying rust and non rust images\",\n",
        "    workspace=ws\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjMl86ZXJFR6",
        "colab_type": "text"
      },
      "source": [
        "## Deploy as a webservice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_W6r7KEJFR7",
        "colab_type": "text"
      },
      "source": [
        "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI.\n",
        "\n",
        "To build the correct environment for ACI, provide the following:\n",
        "\n",
        "1. A scoring script to show how to use the model\n",
        "2. An environment file to show what packages need to be installed\n",
        "3. A configuration file to build the ACI\n",
        "4. The model you trained before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnOXsKf3JFR7",
        "colab_type": "text"
      },
      "source": [
        "### Write a scoring script \n",
        "In order to create a web service, you will create a scoring script that will load the models, perform the prediction, and return the result. Azure ML uses init() and run() functions inside this scoring script for that purpose. The init() function initializes the web service and loads the saved model. The run() function uses the model and the input data to return a prediction which is executed on a scoring call. The init() function should not have any errors otherwise the deployment will fail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ueqca-JJFR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile script.py\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import keras as K\n",
        "import json\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "\n",
        "def init():\n",
        "    \n",
        "    global model  \n",
        "\n",
        "    print(\"Executing init() method...\")\n",
        "    print(\"Python version: \" + str(sys.version) + \", keras version: \" + K.__version__)\n",
        "    # Load the model \n",
        "    #'K.models.load_model('azureml-models/model_name/model_version/model_path')\n",
        "    model = K.models.load_model('azureml-models/kerasmodel/1/kerasmodel.pkl')\n",
        "    \n",
        "    return\n",
        "\n",
        "def predict(model, img):\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict_classes(x)\n",
        "    y = model.predict(x)[0]\n",
        "    y = np.expand_dims(y, axis=-1)\n",
        "    b = []\n",
        "    a = y[0]\n",
        "    b.append(np.float(a))\n",
        "    a = y[1]\n",
        "    b.append(np.float(a))\n",
        "    b.append(preds[0])\n",
        "    return b\n",
        "\n",
        "def run(inputString):\n",
        "    \n",
        "    responses = []\n",
        "    #load the JSON data recieved\n",
        "    base64Dict = json.loads(inputString)\n",
        "    \n",
        "    #the JSON data here was base64 encoded\n",
        "    #so it is decoded first\n",
        "    for k, v in base64Dict.items():\n",
        "        img_file_name, base64Img = k, v\n",
        "    decoded_img = base64.b64decode(base64Img)\n",
        "    img_buffer = BytesIO(decoded_img)\n",
        "    \n",
        "    #load image\n",
        "    img = image.load_img(img_buffer,target_size=(224, 224))\n",
        "    \n",
        "    #make prediction to model\n",
        "    preds = predict(model, img)\n",
        "    LABELS = [\"Non Rust\", \"Rust\"]\n",
        "    resp = LABELS[preds[-1]]\n",
        "    responses.append(preds[0])\n",
        "    responses.append(preds[1])\n",
        "    responses.append(resp)\n",
        "    \n",
        "    #return JSON response\n",
        "    return json.dumps(responses)\n",
        "    \n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "    init()\n",
        "    # input data\n",
        "    img_path = '00000668.JPG'\n",
        "    encoded = None\n",
        "    # data is encoded in base64 \n",
        "    with open(img_path, 'rb') as file:\n",
        "        encoded = base64.b64encode(file.read())\n",
        "    img_dict = {img_path: encoded.decode('utf-8')}\n",
        "    body = json.dumps(img_dict)\n",
        "    resp = run(body)\n",
        "    print(resp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBHvWgVnJFR-",
        "colab_type": "text"
      },
      "source": [
        "### Create environment file\n",
        "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. See the myenv.yml file included, it contains all the dependencies required for this project, you can include further more as well accroding to your needs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTgDSg60JFR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "with open(os.path.join(\"myenv.yml\"),\"r\") as f:\n",
        "    print(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YJH8HxmJFSA",
        "colab_type": "text"
      },
      "source": [
        "### Create ACI configuration\n",
        "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohu5_siqJFSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=2, \n",
        "    memory_gb=2, \n",
        "    tags={\"data\": \"rust\",  \"method\" : \"keras\"}, \n",
        "    description='Predict rust with keras'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogvy5ReEJFSD",
        "colab_type": "text"
      },
      "source": [
        "### Create Docker image\n",
        "Estimated time to complete: about 3-5 minutes\n",
        "\n",
        "Build an image and register that image under the workspace using:\n",
        "\n",
        "1. The scoring file (script.py)\n",
        "2. The environment file (myenv.yml)\n",
        "3. The model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYHrsU5tJFSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from azureml.core.image import ContainerImage\n",
        "\n",
        "# configure the image\n",
        "image_config = ContainerImage.image_configuration(\n",
        "    execution_script=\"script.py\", \n",
        "    runtime=\"python\", \n",
        "    conda_file=\"myenv.yml\"\n",
        ")\n",
        "\n",
        "image = ContainerImage.create(\n",
        "    name = \"keras-rust-img\",\n",
        "    models = [model],\n",
        "    image_config = image_config,\n",
        "    workspace = ws\n",
        ")\n",
        "\n",
        "image.wait_for_creation(show_output = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3rbaNd8JFSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(image.image_location)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i67DZJidJFSH",
        "colab_type": "text"
      },
      "source": [
        "### Deploy the image in ACI\n",
        "Estimated time to complete: about 3-5 minutes\n",
        "\n",
        "The following code goes through these steps:\n",
        "\n",
        "1. Send the image to the ACI container.\n",
        "2. Start up a container in ACI using the image.\n",
        "3. Get the web service HTTP endpoint.\n",
        "\n",
        "Creating and deploying the image, could be done with following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KswRTsA_JFSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from azureml.core.webservice import Webservice\n",
        "\n",
        "aci_service = Webservice.deploy_from_image(\n",
        "    workspace = ws, \n",
        "    name = 'keras-rust-aci-svc',\n",
        "    image = image,\n",
        "    deployment_config = aciconfig\n",
        ")\n",
        "\n",
        "aci_service.wait_for_deployment(show_output=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBhAqIscJFSK",
        "colab_type": "text"
      },
      "source": [
        "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHD7ukptJFSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(aci_service.scoring_uri)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4NJGqhuJFSU",
        "colab_type": "text"
      },
      "source": [
        "### Debugging\n",
        "If the deployment fails it is usually due to errors in scoring python script. You can see the logs by using \" aci_service.get_logs() \" or visit https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-troubleshoot-deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVUBOGRWJFSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aci_service.get_logs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvsW0FgXJFSW",
        "colab_type": "text"
      },
      "source": [
        "You can even refer this github repo https://github.com/SaschaDittmann/TensorFlow101"
      ]
    }
  ]
}